<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>360 Cam Color Tracker</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #000; font-family: sans-serif; }
        
        /* 360 View Background */
        #canvas-container { 
            position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; 
        }

        /* Camera Preview - Bottom Right Corner */
        #camera-ui {
            position: absolute; 
            bottom: 20px; right: 20px; 
            width: 240px; height: 180px;
            z-index: 100;
            border: 2px solid white;
            background: #000;
            box-shadow: 0 0 10px rgba(0,0,0,0.5);
        }

        #input-video {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            object-fit: cover; opacity: 0; /* Hide raw video, show canvas instead */
        }
        
        #output-canvas {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
        }

        /* UI Controls */
        #ui-layer {
            position: absolute; top: 20px; left: 20px; z-index: 101;
        }

        .btn {
            background: rgba(255, 255, 255, 0.9);
            border: none; padding: 10px 20px; margin-bottom: 10px;
            font-size: 16px; font-weight: bold; cursor: pointer;
            display: block; border-radius: 4px;
        }
        
        .status {
            color: lime; background: rgba(0,0,0,0.7); 
            padding: 5px 10px; margin-bottom: 10px; display: inline-block;
        }

        #start-overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            background: rgba(0,0,0,0.8); z-index: 200;
            display: flex; flex-direction: column; justify-content: center; align-items: center;
        }
        
        #start-btn {
            padding: 20px 40px; font-size: 24px; background: #007bff; color: white;
            border: none; border-radius: 8px; cursor: pointer;
        }

        .instruction { color: #ccc; margin-top: 20px; font-size: 14px; max-width: 300px; text-align: center; }
    </style>
    
    <!-- Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- OpenCV.js -->
    <script async src="https://docs.opencv.org/4.5.4/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</head>
<body>

    <!-- Start Screen -->
    <div id="start-overlay">
        <div id="loading-msg" style="color:white; font-size:20px;">Loading OpenCV Library...</div>
        <button id="start-btn" onclick="startSystem()" style="display:none;">START CAMERA</button>
        <div class="instruction">
            1. Allow Camera Access.<br>
            2. Hold a bright <b>RED</b> object in front of the camera.<br>
            3. Move the object left/right/up/down to rotate the view.
        </div>
    </div>

    <!-- UI Controls -->
    <div id="ui-layer">
        <div class="status" id="status-text">Status: Waiting...</div>
        <button class="btn" style="color:red; border-left: 5px solid red;" onclick="setTrackingColor('red')">Track RED</button>
        <button class="btn" style="color:blue; border-left: 5px solid blue;" onclick="setTrackingColor('blue')">Track BLUE</button>
        <button class="btn" style="color:green; border-left: 5px solid green;" onclick="setTrackingColor('green')">Track GREEN</button>
    </div>

    <!-- 360 View -->
    <div id="canvas-container"></div>

    <!-- Camera Preview & Tracking -->
    <div id="camera-ui">
        <video id="input-video" playsinline muted autoplay></video>
        <canvas id="output-canvas"></canvas>
    </div>

<script>
    // --- Config ---
    const IMG_URL = 'https://c1.wallpaperflare.com/preview/926/262/443/astrophotography-death-valley-national-park-photo-nevada.jpg';
    
    // --- Globals ---
    let camera, scene, renderer, sphere;
    let video = document.getElementById('input-video');
    let canvas = document.getElementById('output-canvas');
    let ctx = canvas.getContext('2d');
    let streaming = false;
    let cvReady = false;

    // Tracking Globals
    let cap, src, dst, hsv, mask, contours, hierarchy;
    let low, high; // Color ranges
    let activeColor = 'red';

    // --- 1. System Init ---
    function onOpenCvReady() {
        cvReady = true;
        document.getElementById('loading-msg').style.display = 'none';
        document.getElementById('start-btn').style.display = 'block';
    }

    async function startSystem() {
        document.getElementById('start-overlay').style.display = 'none';
        
        // 1. Start Three.js
        initThreeJS();

        // 2. Start Camera
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { facingMode: 'environment', width: 320, height: 240 }, 
                audio: false 
            });
            video.srcObject = stream;
            video.play();
            
            video.onloadedmetadata = () => {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                streaming = true;
                initTracking(); // Start OpenCV loop
            };
        } catch (err) {
            alert("Camera Error: " + err.message + "\nEnsure you are using HTTPS.");
        }
    }

    // --- 2. Three.js Logic ---
    function initThreeJS() {
        const container = document.getElementById('canvas-container');
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.scale.x = -1; // Invert sphere

        renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        container.appendChild(renderer.domElement);

        const geometry = new THREE.SphereGeometry(500, 60, 40);
        const loader = new THREE.TextureLoader();
        loader.crossOrigin = "anonymous";
        
        loader.load(IMG_URL, (texture) => {
            const material = new THREE.MeshBasicMaterial({ map: texture });
            sphere = new THREE.Mesh(geometry, material);
            scene.add(sphere);
        });

        // Window Resize
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        animate();
    }

    function animate() {
        requestAnimationFrame(animate);
        renderer.render(scene, camera);
    }

    // --- 3. Tracking Logic (OpenCV) ---
    function setTrackingColor(color) {
        activeColor = color;
        document.getElementById('status-text').innerText = "Tracking: " + color.toUpperCase();
        
        // Update HSV ranges based on selection
        if(src) { // Only if opencv initialized
            updateColorRange();
        }
    }

    function updateColorRange() {
        // HSV Ranges (OpenCV scales: H: 0-179, S: 0-255, V: 0-255)
        if (activeColor === 'red') {
            // Red wraps around 0/180. We'll use the lower range 0-10 and upper 170-180 usually, 
            // but a broad 0-15 works well for bright red objects.
            low = new cv.Mat(src.rows, src.cols, src.type(), [0, 100, 100, 0]);
            high = new cv.Mat(src.rows, src.cols, src.type(), [10, 255, 255, 255]);
        } else if (activeColor === 'blue') {
            low = new cv.Mat(src.rows, src.cols, src.type(), [100, 100, 50, 0]);
            high = new cv.Mat(src.rows, src.cols, src.type(), [130, 255, 255, 255]);
        } else if (activeColor === 'green') {
            low = new cv.Mat(src.rows, src.cols, src.type(), [40, 100, 50, 0]);
            high = new cv.Mat(src.rows, src.cols, src.type(), [80, 255, 255, 255]);
        }
    }

    function initTracking() {
        // Initialize Mats
        src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        dst = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        hsv = new cv.Mat();
        mask = new cv.Mat();
        contours = new cv.MatVector();
        hierarchy = new cv.Mat();
        
        // Set initial color
        updateColorRange();
        
        processFrame();
    }

    function processFrame() {
        if (!streaming) return;

        try {
            let begin = Date.now();

            // 1. Read Video
            let cap = new cv.VideoCapture(video);
            cap.read(src);

            // 2. Convert to HSV
            cv.cvtColor(src, hsv, cv.COLOR_RGBA2RGB); // Ensure 3 channels
            cv.cvtColor(hsv, hsv, cv.COLOR_RGB2HSV);

            // 3. Create Mask (Thresholding)
            cv.inRange(hsv, low, high, mask);

            // 4. Morphological opening (remove noise)
            let M = cv.Mat.ones(5, 5, cv.CV_8U);
            cv.erode(mask, mask, M);
            cv.dilate(mask, mask, M);

            // 5. Find Contours
            cv.findContours(mask, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

            // 6. Find Largest Contour (The Object)
            let maxArea = 0;
            let maxCnt = null;

            for (let i = 0; i < contours.size(); ++i) {
                let cnt = contours.get(i);
                let area = cv.contourArea(cnt);
                if (area > 500) { // Minimum size filter
                    if (area > maxArea) {
                        maxArea = area;
                        maxCnt = cnt;
                    }
                }
            }

            // 7. Draw Visuals & Move Camera
            // Clear canvas first
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height); // Draw background video

            if (maxCnt) {
                // Get bounding rect
                let rect = cv.boundingRect(maxCnt);
                
                // Draw Rectangle (Visual Feedback)
                ctx.strokeStyle = activeColor;
                ctx.lineWidth = 4;
                ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
                
                // Draw Center Dot
                let centerX = rect.x + rect.width / 2;
                let centerY = rect.y + rect.height / 2;
                ctx.fillStyle = "white";
                ctx.fillRect(centerX - 5, centerY - 5, 10, 10);

                // --- CAMERA MOVEMENT LOGIC ---
                // Calculate distance from center of screen
                let screenCenterX = canvas.width / 2;
                let screenCenterY = canvas.height / 2;

                // Dead zone (10% of screen) where camera doesn't move
                let deadZone = 30; 

                let diffX = centerX - screenCenterX;
                let diffY = centerY - screenCenterY;

                // Move 3D Camera
                // Sensitivity
                const SENSITIVITY = 0.0005; 

                if (Math.abs(diffX) > deadZone) {
                    camera.rotation.y -= diffX * SENSITIVITY;
                }
                if (Math.abs(diffY) > deadZone) {
                    camera.rotation.x -= diffY * SENSITIVITY;
                }
            } else {
                // No object found
                ctx.fillStyle = "white";
                ctx.font = "20px Arial";
                ctx.fillText("Looking for " + activeColor + "...", 10, 30);
            }

            // Cleanup
            M.delete();
            // Important: Don't delete src/dst/hsv/mask here, we reuse them.
            // But we must clear contours for next frame
            // In C++ opencv contours are vectors, in JS we usually delete and re-init or just let them be overwritten.
            // Safe approach in JS loop:
            contours.delete(); 
            contours = new cv.MatVector(); 

            // Schedule next frame
            requestAnimationFrame(processFrame);

        } catch (err) {
            console.error(err);
        }
    }
</script>
</body>
</html>
